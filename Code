#bash
sudo apt update && sudo apt upgrade -y # 1. Update system
sudo apt install -y python3-pip python3-venv git curl wget # 2. Install essential tools
sudo apt install -y muscle clustalw ncbi-blast+ emboss # 3. Install bioinformatics tools
python3 -m venv lsdv_env # 4. Create virtual environment
source lsdv_env/bin/activate
pip install --upgrade pip # 5. Install Python packages
pip install biopython pandas numpy matplotlib seaborn requests
muscle -version # 6. Test MUSCLE
cd /mnt/d/Bioinformatics/LSDV_Research # Navigate to your new location
python -m venv lsdv_env # Create a new virtual environment here
source lsdv_env/bin/activate # Activate it
pip install biopython pandas matplotlib seaborn numpy # Install required packages
echo "Environment ready on D drive!"

or 

cd /mnt/d/Bioinformatics/LSDV_Research # Navigate to your project directory
sudo apt update # Install required system packages
sudo apt install python3-full python3-venv python3-pip
rm -rf lsdv_env # Remove old venv if it exists
python3 -m venv lsdv_env # Create new virtual environment
source lsdv_env/bin/activate # Activate it
# Verify you're in the venv (should show the venv path)
which python
which pip

# Upgrade pip
pip install --upgrade pip
pip install biopython pandas matplotlib seaborn numpy requests argparse pathlib
python -c "import Bio; print('Biopython installed successfully')"
python -c "import pandas; print('Pandas installed successfully')"
# First, let's see what's in your current directory
ls -la

# Create the Python script file
touch lsdv_downloader.py

# Edit the file with nano (or your preferred editor)
nano lsdv_downloader.py
------------------------------------------------------------------------------------
#paste the code in the nano editor
------------------------------------------------------------------------------------
"""
Enhanced LSDV Raw Data Downloader
Download all LSDV data formats from NCBI for comprehensive analysis
Focuses on Indian data but includes global datasets

File types downloaded:
- Genome sequences (FASTA)
- Annotation features (GTF)
- Annotation features (GFF)
- Sequence and annotation (GBFF)
- Genomic coding sequences (FASTA)
- Protein (FASTA)
- Assembly data report (JSONL)
"""

import pandas as pd
from Bio import Entrez, SeqIO
import os
import sys
import time
import requests
import json
from pathlib import Path
import argparse
from datetime import datetime

# Configuration
YOUR_EMAIL = "ayanhalder198@gmail.com"
OUTPUT_DIRECTORY = "raw_lsdv_data"

class ComprehensiveLSDVDownloader:
    def __init__(self, email):
        Entrez.email = email
        self.api_delay = 0.5  # Be respectful to NCBI
        self.download_stats = {
            'total_sequences': 0,
            'complete_genomes': 0,
            'partial_sequences': 0,
            'proteins': 0,
            'genes': 0,
            'india_sequences': 0
        }
        print(f"üåê Enhanced LSDV Data Downloader initialized")
        print(f"üìß Email: {email}")
        print(f"üéØ Focus: Global LSDV data with emphasis on Indian strains")

    def download_all_lsdv_data(self, output_dir, max_sequences=None):
        """Download comprehensive LSDV dataset in all formats"""
        print("\nüöÄ Starting comprehensive LSDV data download...")
        
        # Create organized directory structure
        self._create_directory_structure(output_dir)
        
        # Download different data types
        results = {}
        
        # 1. Complete genomes (highest priority)
        print("\nüìã STEP 1: Downloading complete genomes...")
        complete_genomes = self._download_complete_genomes(output_dir, max_sequences)
        results['complete_genomes'] = complete_genomes
        
        # 2. All sequences (comprehensive search)
        print("\nüìã STEP 2: Downloading all LSDV sequences...")
        all_sequences = self._download_all_sequences(output_dir, max_sequences)
        results['all_sequences'] = all_sequences
        
        # 3. Protein sequences
        print("\nüìã STEP 3: Downloading protein sequences...")
        proteins = self._download_proteins(output_dir)
        results['proteins'] = proteins
        
        # 4. Gene sequences
        print("\nüìã STEP 4: Downloading gene sequences...")
        genes = self._download_genes(output_dir)
        results['genes'] = genes
        
        # 5. Assembly reports and metadata
        print("\nüìã STEP 5: Downloading assembly reports...")
        assembly_data = self._download_assembly_reports(output_dir)
        results['assembly_data'] = assembly_data
        
        # 6. Generate comprehensive summary
        print("\nüìã STEP 6: Generating comprehensive summary...")
        self._generate_comprehensive_summary(results, output_dir)
        
        return results

    def _create_directory_structure(self, base_dir):
        """Create organized directory structure for different data types"""
        directories = [
            'genome_sequences_fasta',
            'annotation_gtf', 
            'annotation_gff',
            'sequence_annotation_gbff',
            'genomic_cds_fasta',
            'protein_fasta',
            'assembly_reports_jsonl',
            'metadata',
            'india_specific',
            'summary_reports'
        ]
        
        for dir_name in directories:
            dir_path = os.path.join(base_dir, dir_name)
            os.makedirs(dir_path, exist_ok=True)
            print(f"  üìÅ Created: {dir_name}/")

    def _download_complete_genomes(self, output_dir, max_sequences):
        """Download complete LSDV genomes in multiple formats"""
        search_strategies = [
            'Lumpy skin disease virus[Organism] AND complete genome',
            'Capripoxvirus[Organism] AND lumpy skin disease AND complete genome',
            'LSDV[All Fields] AND complete genome'
        ]
        
        all_ids = set()
        
        for strategy in search_strategies:
            print(f"  üîç Searching: {strategy}")
            time.sleep(self.api_delay)
            
            try:
                handle = Entrez.esearch(
                    db="nucleotide",
                    term=strategy,
                    retmax=1000,
                    sort="relevance"
                )
                results = Entrez.read(handle)
                handle.close()
                
                new_ids = results["IdList"]
                all_ids.update(new_ids)
                print(f"    ‚úÖ Found: {len(new_ids)} sequences")
                
            except Exception as e:
                print(f"    ‚ùå Search failed: {e}")
                continue
        
        final_ids = list(all_ids)
        if max_sequences:
            final_ids = final_ids[:max_sequences]
        
        print(f"üìä Downloading {len(final_ids)} complete genomes in multiple formats...")
        
        # Download in multiple formats
        genome_data = self._download_multi_format(final_ids, output_dir, "complete_genomes")
        self.download_stats['complete_genomes'] = len(final_ids)
        
        return genome_data

    def _download_all_sequences(self, output_dir, max_sequences):
        """Download all LSDV sequences with geographic focus"""
        search_strategies = [
            # General searches
            'Lumpy skin disease virus[Organism]',
            'LSDV[All Fields]',
            'txid928302[Organism]',
            
            # Geographic searches (India focus)
            'Lumpy skin disease virus[Organism] AND India',
            'Lumpy skin disease virus[Organism] AND Pakistan',
            'Lumpy skin disease virus[Organism] AND Bangladesh',
            'Lumpy skin disease virus[Organism] AND Nepal',
            'Lumpy skin disease virus[Organism] AND Sri Lanka',
            'Lumpy skin disease virus[Organism] AND Thailand',
            'Lumpy skin disease virus[Organism] AND China',
            'Lumpy skin disease virus[Organism] AND Myanmar',
            'Lumpy skin disease virus[Organism] AND Vietnam',
            
            # Sequence types
            'Lumpy skin disease virus[Organism] AND partial',
            'Lumpy skin disease virus[Organism] AND gene',
            'Lumpy skin disease virus[Organism] AND CDS',
            
            # Recent sequences
            'Lumpy skin disease virus[Organism] AND ("2020"[Date] : "2025"[Date])',
            'Lumpy skin disease virus[Organism] AND ("2023"[Date] : "2025"[Date])',
        ]
        
        all_ids = set()
        india_specific = set()
        
        for strategy in search_strategies:
            print(f"  üîç Searching: {strategy}")
            time.sleep(self.api_delay)
            
            try:
                handle = Entrez.esearch(
                    db="nucleotide",
                    term=strategy,
                    retmax=10000,
                    sort="relevance"
                )
                results = Entrez.read(handle)
                handle.close()
                
                new_ids = results["IdList"]
                all_ids.update(new_ids)
                
                # Track India-specific sequences
                if 'India' in strategy:
                    india_specific.update(new_ids)
                
                print(f"    ‚úÖ Found: {len(new_ids)} sequences (Total: {len(all_ids)})")
                
            except Exception as e:
                print(f"    ‚ùå Search failed: {e}")
                continue
        
        final_ids = list(all_ids)
        if max_sequences:
            final_ids = final_ids[:max_sequences]
        
        self.download_stats['total_sequences'] = len(final_ids)
        self.download_stats['india_sequences'] = len(india_specific)
        
        print(f"üìä Total sequences: {len(final_ids)}")
        print(f"üáÆüá≥ India-specific sequences: {len(india_specific)}")
        
        # Download sequences
        sequence_data = self._download_multi_format(final_ids, output_dir, "all_sequences")
        
        # Separate India-specific data
        if india_specific:
            india_ids = list(india_specific)
            india_data = self._download_multi_format(india_ids, output_dir, "india_specific")
            sequence_data['india_specific'] = india_data
        
        return sequence_data

    def _download_proteins(self, output_dir):
        """Download protein sequences from LSDV genomes"""
        print("  üß¨ Searching for LSDV proteins...")
        
        search_strategies = [
            'Lumpy skin disease virus[Organism] AND protein',
            'Lumpy skin disease virus[Organism] AND CDS',
            'LSDV[All Fields] AND protein'
        ]
        
        all_ids = set()
        
        for strategy in search_strategies:
            print(f"    üîç {strategy}")
            time.sleep(self.api_delay)
            
            try:
                handle = Entrez.esearch(
                    db="protein",  # Search protein database
                    term=strategy,
                    retmax=5000
                )
                results = Entrez.read(handle)
                handle.close()
                
                new_ids = results["IdList"]
                all_ids.update(new_ids)
                print(f"      ‚úÖ Found: {len(new_ids)} proteins")
                
            except Exception as e:
                print(f"      ‚ùå Failed: {e}")
                continue
        
        protein_ids = list(all_ids)
        self.download_stats['proteins'] = len(protein_ids)
        
        if protein_ids:
            # Download protein sequences
            protein_data = self._download_protein_sequences(protein_ids, output_dir)
            return protein_data
        
        return []

    def _download_genes(self, output_dir):
        """Download gene sequences"""
        print("  üß¨ Searching for LSDV genes...")
        
        search_term = 'Lumpy skin disease virus[Organism] AND gene'
        
        try:
            handle = Entrez.esearch(
                db="nucleotide",
                term=search_term,
                retmax=5000
            )
            results = Entrez.read(handle)
            handle.close()
            
            gene_ids = results["IdList"]
            self.download_stats['genes'] = len(gene_ids)
            
            if gene_ids:
                gene_data = self._download_multi_format(gene_ids, output_dir, "genes")
                return gene_data
                
        except Exception as e:
            print(f"    ‚ùå Gene search failed: {e}")
        
        return []

    def _download_multi_format(self, sequence_ids, output_dir, data_type):
        """Download sequences in multiple formats (FASTA, GenBank, GFF, etc.)"""
        if not sequence_ids:
            return []
        
        print(f"  üì• Downloading {len(sequence_ids)} sequences in multiple formats...")
        
        batch_size = 50
        all_sequences = []
        all_metadata = []
        
        for i in range(0, len(sequence_ids), batch_size):
            batch = sequence_ids[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(sequence_ids) + batch_size - 1) // batch_size
            
            print(f"    üì¶ Batch {batch_num}/{total_batches}")
            time.sleep(self.api_delay)
            
            try:
                # 1. Download FASTA sequences
                fasta_sequences = self._download_fasta_batch(batch, output_dir, data_type, batch_num)
                all_sequences.extend(fasta_sequences)
                
                # 2. Download GenBank format (GBFF)
                self._download_genbank_batch(batch, output_dir, data_type, batch_num)
                
                # 3. Extract metadata
                metadata = self._extract_metadata_batch(batch)
                all_metadata.extend(metadata)
                
                # 4. Download GFF annotations (for complete genomes)
                if data_type == "complete_genomes":
                    self._download_gff_batch(batch, output_dir, batch_num)
                
                print(f"      ‚úÖ Downloaded {len(fasta_sequences)} sequences")
                
            except Exception as e:
                print(f"      ‚ùå Batch {batch_num} failed: {e}")
                continue
        
        # Save consolidated data
        self._save_consolidated_data(all_sequences, all_metadata, output_dir, data_type)
        
        return {
            'sequences': all_sequences,
            'metadata': all_metadata,
            'count': len(all_sequences)
        }

    def _download_fasta_batch(self, batch_ids, output_dir, data_type, batch_num):
        """Download FASTA sequences for a batch"""
        try:
            handle = Entrez.efetch(
                db="nucleotide",
                id=",".join(batch_ids),
                rettype="fasta",
                retmode="text"
            )
            
            sequences = list(SeqIO.parse(handle, "fasta"))
            handle.close()
            
            # Save batch file
            fasta_dir = os.path.join(output_dir, "genome_sequences_fasta")
            batch_file = os.path.join(fasta_dir, f"{data_type}_batch_{batch_num}.fasta")
            SeqIO.write(sequences, batch_file, "fasta")
            
            return sequences
            
        except Exception as e:
            print(f"        ‚ùå FASTA download failed: {e}")
            return []

    def _download_genbank_batch(self, batch_ids, output_dir, data_type, batch_num):
        """Download GenBank format (GBFF) for a batch"""
        try:
            handle = Entrez.efetch(
                db="nucleotide",
                id=",".join(batch_ids),
                rettype="gb",
                retmode="text"
            )
            
            gbff_content = handle.read()
            handle.close()
            
            # Save GBFF file
            gbff_dir = os.path.join(output_dir, "sequence_annotation_gbff")
            gbff_file = os.path.join(gbff_dir, f"{data_type}_batch_{batch_num}.gbff")
            
            with open(gbff_file, 'w') as f:
                f.write(gbff_content)
            
        except Exception as e:
            print(f"        ‚ùå GBFF download failed: {e}")

    def _download_gff_batch(self, batch_ids, output_dir, batch_num):
        """Download GFF annotations (limited availability for viral genomes)"""
        # Note: GFF files are not always available for viral genomes from NCBI
        # This is a placeholder for when they become available
        pass

    def _download_protein_sequences(self, protein_ids, output_dir):
        """Download protein sequences"""
        print(f"  üì• Downloading {len(protein_ids)} protein sequences...")
        
        batch_size = 100
        all_proteins = []
        
        for i in range(0, len(protein_ids), batch_size):
            batch = protein_ids[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"    üì¶ Protein batch {batch_num}")
            time.sleep(self.api_delay)
            
            try:
                handle = Entrez.efetch(
                    db="protein",
                    id=",".join(batch),
                    rettype="fasta",
                    retmode="text"
                )
                
                proteins = list(SeqIO.parse(handle, "fasta"))
                all_proteins.extend(proteins)
                handle.close()
                
                # Save batch
                protein_dir = os.path.join(output_dir, "protein_fasta")
                batch_file = os.path.join(protein_dir, f"proteins_batch_{batch_num}.fasta")
                SeqIO.write(proteins, batch_file, "fasta")
                
            except Exception as e:
                print(f"      ‚ùå Protein batch {batch_num} failed: {e}")
                continue
        
        # Save all proteins
        if all_proteins:
            protein_dir = os.path.join(output_dir, "protein_fasta")
            all_proteins_file = os.path.join(protein_dir, "all_lsdv_proteins.fasta")
            SeqIO.write(all_proteins, all_proteins_file, "fasta")
        
        return all_proteins

    def _extract_metadata_batch(self, batch_ids):
        """Extract comprehensive metadata for a batch"""
        try:
            handle = Entrez.efetch(
                db="nucleotide",
                id=",".join(batch_ids),
                rettype="gb",
                retmode="text"
            )
            
            records = list(SeqIO.parse(handle, "genbank"))
            handle.close()
            
            metadata = []
            for record in records:
                meta = self._extract_comprehensive_metadata(record)
                metadata.append(meta)
            
            return metadata
            
        except Exception as e:
            print(f"        ‚ùå Metadata extraction failed: {e}")
            return []

    def _extract_comprehensive_metadata(self, record):
        """Extract comprehensive metadata from a GenBank record"""
        metadata = {
            'accession': record.id,
            'description': record.description,
            'length': len(record.seq),
            'organism': record.annotations.get('organism', 'Unknown'),
            'taxonomy': str(record.annotations.get('taxonomy', [])),
            'date': record.annotations.get('date', 'Unknown'),
            'country': 'Unknown',
            'collection_date': 'Unknown',
            'host': 'Unknown',
            'strain': 'Unknown',
            'isolate': 'Unknown',
            'collected_by': 'Unknown',
            'lab_host': 'Unknown',
            'note': 'Unknown',
            'tissue_type': 'Unknown',
            'dev_stage': 'Unknown',
            'mol_type': 'Unknown',
            'isolation_source': 'Unknown'
        }
        
        # Extract source information
        for feature in record.features:
            if feature.type == "source":
                qualifiers = feature.qualifiers
                
                # Basic info
                metadata['country'] = qualifiers.get('country', ['Unknown'])[0]
                metadata['collection_date'] = qualifiers.get('collection_date', ['Unknown'])[0]
                metadata['host'] = qualifiers.get('host', ['Unknown'])[0]
                metadata['strain'] = qualifiers.get('strain', ['Unknown'])[0]
                metadata['isolate'] = qualifiers.get('isolate', ['Unknown'])[0]
                
                # Extended info
                metadata['collected_by'] = qualifiers.get('collected_by', ['Unknown'])[0]
                metadata['lab_host'] = qualifiers.get('lab_host', ['Unknown'])[0]
                metadata['note'] = str(qualifiers.get('note', ['Unknown']))
                metadata['tissue_type'] = qualifiers.get('tissue_type', ['Unknown'])[0]
                metadata['dev_stage'] = qualifiers.get('dev_stage', ['Unknown'])[0]
                metadata['mol_type'] = qualifiers.get('mol_type', ['Unknown'])[0]
                metadata['isolation_source'] = qualifiers.get('isolation_source', ['Unknown'])[0]
                
                break
        
        # Clean country name
        if ':' in metadata['country']:
            metadata['country'] = metadata['country'].split(':')[0].strip()
        
        # Detect India and Indian states
        text_to_check = f"{metadata['description']} {metadata['isolate']} {metadata['strain']} {metadata['country']} {metadata['note']}"
        if self._is_india_related(text_to_check):
            metadata['country'] = 'India'
            metadata['india_specific'] = True
        else:
            metadata['india_specific'] = False
        
        # Classify sequence type
        metadata['sequence_type'] = self._classify_sequence_type(metadata['description'], metadata['length'])
        
        return metadata

    def _is_india_related(self, text):
        """Check if sequence is related to India"""
        india_terms = [
            'india', 'indian', 'karnataka', 'arunachal pradesh', 'maharashtra', 
            'gujarat', 'punjab', 'rajasthan', 'uttar pradesh', 'bihar', 
            'west bengal', 'odisha', 'andhra pradesh', 'telangana', 'kerala', 
            'tamil nadu', 'madhya pradesh', 'chhattisgarh', 'jharkhand', 
            'assam', 'manipur', 'nagaland', 'mizoram', 'tripura', 'sikkim',
            'himachal pradesh', 'uttarakhand', 'goa', 'haryana', 'delhi',
            'jammu and kashmir', 'ladakh'
        ]
        
        text_lower = text.lower()
        return any(term in text_lower for term in india_terms)

    def _classify_sequence_type(self, description, length):
        """Classify sequence type"""
        desc_lower = description.lower()
        
        if 'complete genome' in desc_lower:
            return 'Complete Genome'
        elif length > 100000:
            return 'Complete Genome'
        elif 'partial' in desc_lower:
            return 'Partial Sequence'
        elif 'gene' in desc_lower:
            return 'Gene Sequence'
        elif 'protein' in desc_lower:
            return 'Protein Sequence'
        elif 'cds' in desc_lower:
            return 'Coding Sequence'
        elif length < 5000:
            return 'Short Sequence'
        else:
            return 'Unknown'

    def _download_assembly_reports(self, output_dir):
        """Download assembly reports in JSONL format"""
        print("  üìã Generating assembly reports...")
        
        # Create assembly report with all collected metadata
        assembly_dir = os.path.join(output_dir, "assembly_reports_jsonl")
        
        # This would contain summary statistics and assembly information
        # For now, we'll create a placeholder structure
        assembly_report = {
            'download_date': datetime.now().isoformat(),
            'stats': self.download_stats,
            'data_types': [
                'genome_sequences_fasta',
                'sequence_annotation_gbff', 
                'protein_fasta',
                'assembly_reports_jsonl'
            ]
        }
        
        report_file = os.path.join(assembly_dir, "download_assembly_report.json")
        with open(report_file, 'w') as f:
            json.dump(assembly_report, f, indent=2)
        
        return assembly_report

    def _save_consolidated_data(self, sequences, metadata, output_dir, data_type):
        """Save consolidated data files"""
        if not sequences:
            return
        
        # Save all sequences in one file
        fasta_dir = os.path.join(output_dir, "genome_sequences_fasta")
        consolidated_fasta = os.path.join(fasta_dir, f"all_{data_type}.fasta")
        SeqIO.write(sequences, consolidated_fasta, "fasta")
        
        # Save metadata
        if metadata:
            metadata_dir = os.path.join(output_dir, "metadata")
            metadata_file = os.path.join(metadata_dir, f"{data_type}_metadata.csv")
            metadata_df = pd.DataFrame(metadata)
            metadata_df.to_csv(metadata_file, index=False)
            
            # Save India-specific metadata
            india_metadata = [m for m in metadata if m.get('india_specific', False)]
            if india_metadata:
                india_file = os.path.join(metadata_dir, f"{data_type}_india_metadata.csv")
                pd.DataFrame(india_metadata).to_csv(india_file, index=False)

    def _generate_comprehensive_summary(self, results, output_dir):
        """Generate comprehensive analysis summary"""
        summary_dir = os.path.join(output_dir, "summary_reports")
        
        # Create detailed summary
        summary = {
            'download_info': {
                'date': datetime.now().isoformat(),
                'email': YOUR_EMAIL,
                'total_sequences': self.download_stats['total_sequences'],
                'complete_genomes': self.download_stats['complete_genomes'],
                'proteins': self.download_stats['proteins'],
                'genes': self.download_stats['genes'],
                'india_sequences': self.download_stats['india_sequences']
            },
            'file_structure': {
                'genome_sequences_fasta': 'FASTA format genome sequences',
                'sequence_annotation_gbff': 'GenBank flat file format with annotations',
                'protein_fasta': 'Protein sequences in FASTA format',
                'metadata': 'CSV files with comprehensive metadata',
                'india_specific': 'India-specific sequences and metadata',
                'assembly_reports_jsonl': 'Assembly and download reports'
            },
            'geographic_focus': {
                'primary_focus': 'India',
                'secondary_regions': ['Pakistan', 'Bangladesh', 'Nepal', 'Sri Lanka', 'Southeast Asia'],
                'india_data_percentage': (self.download_stats['india_sequences'] / max(self.download_stats['total_sequences'], 1)) * 100
            },
            'data_quality': {
                'complete_genomes_ratio': (self.download_stats['complete_genomes'] / max(self.download_stats['total_sequences'], 1)) * 100,
                'protein_coverage': self.download_stats['proteins'] > 0,
                'metadata_completeness': 'Comprehensive metadata extracted for all sequences'
            }
        }
        
        # Save JSON summary
        summary_file = os.path.join(summary_dir, "comprehensive_summary.json")
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        # Save text summary
        text_summary_file = os.path.join(summary_dir, "download_summary.txt")
        with open(text_summary_file, 'w') as f:
            f.write("COMPREHENSIVE LSDV RAW DATA DOWNLOAD SUMMARY\n")
            f.write("="*50 + "\n\n")
            
            f.write("DOWNLOAD STATISTICS:\n")
            f.write("-"*20 + "\n")
            f.write(f"Total sequences: {self.download_stats['total_sequences']}\n")
            f.write(f"Complete genomes: {self.download_stats['complete_genomes']}\n")
            f.write(f"Protein sequences: {self.download_stats['proteins']}\n")
            f.write(f"Gene sequences: {self.download_stats['genes']}\n")
            f.write(f"India-specific sequences: {self.download_stats['india_sequences']}\n\n")
            
            f.write("INDIA FOCUS:\n")
            f.write("-"*12 + "\n")
            f.write(f"India data percentage: {summary['geographic_focus']['india_data_percentage']:.1f}%\n")
            f.write(f"Complete genomes ratio: {summary['data_quality']['complete_genomes_ratio']:.1f}%\n\n")
            
            f.write("FILE FORMATS DOWNLOADED:\n")
            f.write("-"*25 + "\n")
            f.write("‚úÖ Genome sequences (FASTA)\n")
            f.write("‚úÖ Sequence and annotation (GBFF)\n") 
            f.write("‚úÖ Protein sequences (FASTA)\n")
            f.write("‚úÖ Assembly data reports (JSON)\n")
            f.write("‚úÖ Comprehensive metadata (CSV)\n\n")
            
            f.write("READY FOR ANALYSIS:\n")
            f.write("-"*18 + "\n")
            f.write("‚úÖ Mutation analysis\n")
            f.write("‚úÖ Geographic distribution analysis\n")
            f.write("‚úÖ Phylogenetic studies\n")
            f.write("‚úÖ Indian strain characterization\n")
            f.write("‚úÖ Abundance region mapping\n")
        
        # Print summary to console
        print(f"\nüìä DOWNLOAD COMPLETE!")
        print(f"="*50)
        print(f"üìÅ Data saved to: {output_dir}")
        print(f"üìä Total sequences: {self.download_stats['total_sequences']}")
        print(f"üß¨ Complete genomes: {self.download_stats['complete_genomes']}")
        print(f"üáÆüá≥ India-specific: {self.download_stats['india_sequences']}")
        print(f"üß™ Proteins: {self.download_stats['proteins']}")
        print(f"üìã Summary: {text_summary_file}")

def main():
    """Main function to download comprehensive LSDV raw data"""
    parser = argparse.ArgumentParser(description="Download Comprehensive LSDV Raw Data")
    parser.add_argument("--email", default=YOUR_EMAIL, help="Email for NCBI access")
    parser.add_argument("--output", default=OUTPUT_DIRECTORY, help="Output directory")
    parser.add_argument("--max-sequences", type=int, help="Maximum sequences per category")
    parser.add_argument("--test-run", action="store_true", help="Test run with limited data")
    
    args = parser.parse_args()
    
    print("üß¨ COMPREHENSIVE LSDV RAW DATA DOWNLOADER")
    print("="*50)
    print("üéØ Downloading all LSDV data formats for comprehensive analysis")
    print("üáÆüá≥ Special focus on Indian strains")
    print(f"üìß Email: {args.email}")
    print(f"üìÅ Output: {args.output}")
    if args.max_sequences:
        print(f"üî¢ Max sequences per category: {args.max_sequences}")
    if args.test_run:
        print("üß™ Test run mode - limited sequences")
    
    # Setup
    output_dir = os.path.expanduser(args.output)
    os.makedirs(output_dir, exist_ok=True)
    
    # Initialize downloader
    downloader = ComprehensiveLSDVDownloader(args.email)
    
    try:
        # Set limits for test run
        max_sequences = args.max_sequences
        if args.test_run:
            max_sequences = 10
            print("üß™ Test run: limiting to 10 sequences per category")
        
        # Start comprehensive download
        results = downloader.download_all_lsdv_data(output_dir, max_sequences)
        
        print("\n" + "="*50)
        print("üéâ COMPREHENSIVE DOWNLOAD COMPLETE!")
        print("="*50)
        print(f"üìÅ All data saved to: {output_dir}")
        
        # Show directory structure
        print(f"\nüìÇ Directory structure:")
        for root, dirs, files in os.walk(output_dir):
            level = root.replace(output_dir, '').count(os.sep)
            indent = ' ' * 2 * level
            print(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files[:3]:  # Show first 3 files
                print(f"{subindent}{file}")
            if len(files) > 3:
                print(f"{subindent}... and {len(files)-3} more files")
        
        # Show final statistics
        print(f"\nüìä FINAL STATISTICS:")
        print(f"   Total sequences: {downloader.download_stats['total_sequences']}")
        print(f"   Complete genomes: {downloader.download_stats['complete_genomes']}")
        print(f"   Protein sequences: {downloader.download_stats['proteins']}")
        print(f"   Gene sequences: {downloader.download_stats['genes']}")
        print(f"   India-specific: {downloader.download_stats['india_sequences']}")
        
        # Next steps
        print(f"\nüî¨ READY FOR ANALYSIS:")
        print(f"   ‚úÖ Mutation analysis ready")
        print(f"   ‚úÖ Geographic distribution mapping ready")
        print(f"   ‚úÖ Phylogenetic analysis ready")
        print(f"   ‚úÖ Indian strain characterization ready")
        print(f"   ‚úÖ Abundance region mapping ready")
        
        print(f"\nüìã Check summary_reports/download_summary.txt for detailed information")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Download interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Download failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
-------------------------------------------------------------------------------------
Till this
--------------------------------------------------------------------------------------
